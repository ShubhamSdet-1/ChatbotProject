{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install pypdf2\n",
    "# !pip install langchain-community \n",
    "# !pip install unstructured\n",
    "# !pip install \"unstructured[pdf]\"\n",
    "# !apt-get install poppler-utils\n",
    "# !apt-get install tesseract-ocr\n",
    "# !apt-get install libtesseract-dev\n",
    "\n",
    "# !pip install faiss-cpu\n",
    "# !pip install sentence-transformers\n",
    "\n",
    "# !pip install langchain-huggingface\n",
    "\n",
    "# !pip install huggingface_hub\n",
    "\n",
    "# !pip install transformers\n",
    "\n",
    "# !pip install accelerate\n",
    "\n",
    "# !pip install bitsandbytes\n",
    "\n",
    "# !pip install python-dotenv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "Data_path = \"C:/Users/srajp/OneDrive/Desktop/GenAI/ChatBot/Content/\"\n",
    "def load_documents(Data_path):\n",
    "  loader = DirectoryLoader(Data_path,glob=\"**/*.pdf\")\n",
    "  documents = loader.load()\n",
    "  return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pickle\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200,length_function=len,add_start_index=True)\n",
    "documents = load_documents(Data_path)\n",
    "print(len(documents))\n",
    "texts = text_splitter.split_documents(documents)\n",
    "with open('texts.pkl', 'wb') as f:\n",
    "    pickle.dump(texts, f)\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "723\n"
     ]
    }
   ],
   "source": [
    "##import locally stored split data\n",
    "import pickle\n",
    "text_Path = \"split_data/texts.pkl\"\n",
    "with open(text_Path, 'rb') as f:\n",
    "    texts1 = pickle.load(f)\n",
    "print(len(texts1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUNDATIONS OF SOFTWARE TESTING\n",
      "\n",
      "ISTQB CERTIFICATION\n",
      "\n",
      "Dorothy Graham\n",
      "\n",
      "Erik van Veenendaal\n",
      "\n",
      "Isabel Evans\n",
      "\n",
      "Rex Black\n",
      "\n",
      "CONTENTS\n",
      "\n",
      "Acknowledgements viii Preface ix\n",
      "\n",
      "1 Fundamentals of testing 1\n",
      "\n",
      "1.1 Why is testing necessary? 1 1.2 What is testing? 11 1.3 Testing principles 18 1.4 Fundamental test process 20 1.5 The psychology of testing 26 Chapter review 31 Sample exam questions 32 Exercise: Test psychology 33 Exercise solution 34\n",
      "\n",
      "2 Testing throughout the software life cycle 35\n",
      "\n",
      "2.1 Software development models 35 2.2 Test levels 41 2.3 Test types: the targets of testing 46 2.4 Maintenance testing 50 Chapter review 54 Sample exam questions 55\n",
      "\n",
      "3 Static techniques 57 3.1 Reviews and the test process 57\n",
      "\n",
      "3.2 Review process 59 3.3 Static analysis by tools 69 Chapter review 74 Sample exam questions 75\n",
      "\n",
      "4 Test design techniques 77\n",
      "Metadata - {'source': '/content/sample_data/Foundations of software testing.pdf', 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "print(texts1[1].page_content)\n",
    "print(\"Metadata -\",texts1[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Replace with the desired model name\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "# Create FAISS vectorstore\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "db.save_local(\"Vector_db/faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load locally store vector_db back\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Replace with the desired model name\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "db1 = FAISS.load_local(\"Vector_db/faiss_index\", embeddings, allow_dangerous_deserialization=True) # Set allow_dangerous_deserialization to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Importance ISTQB Certificate in IT?\"\n",
    "results = db1.similarity_search_with_relevance_scores(question,k=3)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text, question=question)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "secKey = os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "# print(secKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API token\n",
    "api_token = os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "if api_token is None:\n",
    "    print(\"Error: HUGGINGFACEHUB_API_TOKEN not found in .env file.\")\n",
    "else:\n",
    "    # Use the API token here\n",
    "    print(f\"API token retrieved: {api_token[:5]}... (truncated for security)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ['HUGGINGFACEHUB_API_TOKEN'] = secKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_huggingface\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "repo_id =\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm = HuggingFaceEndpoint(repo_id=repo_id, temperature=0.1, max_length=512, token=secKey) # Pass temperature and max_length as separate arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "output = llm.invoke(prompt)\n",
    "# print(output)\n",
    "cleaned_output = output.replace(\"'\", \"\").replace(\"\\n\", \" \")\n",
    "print(cleaned_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
